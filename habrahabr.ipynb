{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adashaw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe0714df5486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNadam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Merge'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.despine()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Merge\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AtrousConvolution1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras import regularizers\n",
    "\n",
    "import theano\n",
    "theano.config.compute_test_value = \"ignore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # courtsey http://stackoverflow.com/users/190280/josh-bleecher-snyder\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    " \n",
    "def create_Xt_Yt(X, y, percentage=0.9):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "     \n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    " \n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(print e)? (<ipython-input-2-34fec9799bdc>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-34fec9799bdc>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    print e\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(print e)?\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('AAPL.csv')[::-1]\n",
    "data = data.ix[:, 'Adj Close'].tolist()\n",
    "\n",
    "# Uncomment below to use price change time series\n",
    "# data = data.ix[:, 'Adj Close'].pct_change().dropna().tolist()\n",
    "\n",
    "plt.plot(data)\n",
    "plt.show()\n",
    "\n",
    "WINDOW = 30\n",
    "EMB_SIZE = 1\n",
    "STEP = 1\n",
    "FORECAST = 5\n",
    "\n",
    "# Straightforward way for creating time windows\n",
    "X, Y = [], []\n",
    "for i in range(0, len(data), STEP): \n",
    "    try:\n",
    "        x_i = data[i:i+WINDOW]\n",
    "        y_i = data[i+WINDOW+FORECAST]  \n",
    "\n",
    "        last_close = x_i[WINDOW-1]\n",
    "        next_close = y_i\n",
    "\n",
    "        if last_close < next_close:\n",
    "            y_i = [1, 0]\n",
    "        else:\n",
    "            y_i = [0, 1] \n",
    "\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        break\n",
    "\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "\n",
    "X = [(np.array(x) - np.mean(x)) / np.std(x) for x in X] # comment it to remove normalization\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=30,\n",
    "                activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16,\n",
    "                activity_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = Nadam(lr=0.001)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 1, \n",
    "          batch_size = 128, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred = model.predict(np.array(X_test))\n",
    "C = confusion_matrix([np.argmax(y) for y in Y_test], [np.argmax(y) for y in pred])\n",
    "\n",
    "print C / C.astype(np.float).sum(axis=1)\n",
    "\n",
    "FROM = 0\n",
    "TO = FROM + 500\n",
    "\n",
    "original = Y_test[FROM:TO]\n",
    "predicted = pred[FROM:TO] \n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted from point %d to point %d of test set' % (FROM, TO))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
