{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "8fa4d3ab-d84c-454e-b147-bbec7e16d8fd",
    "_uuid": "edaf59c5ec111bf128089f906d74db55d9aa22e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adashaw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ls', '../input']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b1a93b1dc6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 336\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 418\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ls', '../input']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_stocks_5yr.csv')\n",
    "cl = data[data['Name']=='MMM'].close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adashaw/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00580061],\n",
       "       [0.00554564],\n",
       "       [0.01090005],\n",
       "       ...,\n",
       "       [0.82668281],\n",
       "       [0.84064253],\n",
       "       [0.83783784]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl = MinMaxScaler()\n",
    "#Scale the data\n",
    "cl = cl.reshape(cl.shape[0],1)\n",
    "cl = scl.fit_transform(cl)\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "251\n",
      "1000\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "#Create a function to process the data into 7 day look back slices\n",
    "def processData(data,lb):\n",
    "    X,Y = [],[]\n",
    "    for i in range(len(data)-lb-1):\n",
    "        X.append(data[i:(i+lb),0])\n",
    "        Y.append(data[(i+lb),0])\n",
    "    return np.array(X),np.array(Y)\n",
    "X,y = processData(cl,7)\n",
    "X_train,X_test = X[:int(X.shape[0]*0.80)],X[int(X.shape[0]*0.80):]\n",
    "y_train,y_test = y[:int(y.shape[0]*0.80)],y[int(y.shape[0]*0.80):]\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "print(y_train.shape[0])\n",
    "print(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 251 samples\n",
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 0.0255\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 0s 406us/step - loss: 0.0065 - val_loss: 0.0013\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 0s 399us/step - loss: 0.0032 - val_loss: 6.9154e-04\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 0s 408us/step - loss: 4.0903e-04 - val_loss: 0.0016\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 0s 400us/step - loss: 3.5175e-04 - val_loss: 9.6537e-04\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 0s 400us/step - loss: 6.0145e-04 - val_loss: 6.2792e-04\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 0s 402us/step - loss: 3.8164e-04 - val_loss: 9.9315e-04\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 4.3866e-04 - val_loss: 0.0012\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 0s 458us/step - loss: 6.3276e-04 - val_loss: 0.0011\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 0s 444us/step - loss: 6.7576e-04 - val_loss: 0.0012\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 0s 466us/step - loss: 6.1794e-04 - val_loss: 0.0014\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 5.3906e-04 - val_loss: 0.0016\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 5.0026e-04 - val_loss: 0.0018\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 4.7774e-04 - val_loss: 0.0020\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 0s 406us/step - loss: 4.6132e-04 - val_loss: 0.0021\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 0s 409us/step - loss: 4.4550e-04 - val_loss: 0.0023\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 0s 406us/step - loss: 4.3126e-04 - val_loss: 0.0024\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 0s 403us/step - loss: 4.1930e-04 - val_loss: 0.0025\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 4.0903e-04 - val_loss: 0.0027\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 0s 427us/step - loss: 4.0134e-04 - val_loss: 0.0028\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 0s 413us/step - loss: 3.9550e-04 - val_loss: 0.0028\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 0s 417us/step - loss: 3.9056e-04 - val_loss: 0.0029\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 3.8717e-04 - val_loss: 0.0029\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 0s 410us/step - loss: 3.8426e-04 - val_loss: 0.0030\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 3.8226e-04 - val_loss: 0.0030\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 3.7988e-04 - val_loss: 0.0030\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 0s 416us/step - loss: 3.7850e-04 - val_loss: 0.0030\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 0s 420us/step - loss: 3.7538e-04 - val_loss: 0.0031\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 3.7453e-04 - val_loss: 0.0030\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 3.7027e-04 - val_loss: 0.0030\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 0s 413us/step - loss: 3.7023e-04 - val_loss: 0.0030\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 0s 406us/step - loss: 3.6410e-04 - val_loss: 0.0030\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 0s 418us/step - loss: 3.6586e-04 - val_loss: 0.0030\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 3.5636e-04 - val_loss: 0.0030\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 0s 413us/step - loss: 3.6216e-04 - val_loss: 0.0029\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 0s 412us/step - loss: 3.4654e-04 - val_loss: 0.0029\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 3.6074e-04 - val_loss: 0.0028\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 3.3346e-04 - val_loss: 0.0029\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 0s 412us/step - loss: 3.6297e-04 - val_loss: 0.0027\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 0s 421us/step - loss: 3.1646e-04 - val_loss: 0.0029\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 0s 411us/step - loss: 3.7416e-04 - val_loss: 0.0026\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 0s 427us/step - loss: 2.9662e-04 - val_loss: 0.0030\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 0s 417us/step - loss: 3.9966e-04 - val_loss: 0.0025\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 0s 422us/step - loss: 2.8538e-04 - val_loss: 0.0032\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 0s 442us/step - loss: 4.3832e-04 - val_loss: 0.0024\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 0s 413us/step - loss: 3.1950e-04 - val_loss: 0.0033\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 0s 455us/step - loss: 4.6091e-04 - val_loss: 0.0025\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 0s 490us/step - loss: 4.0019e-04 - val_loss: 0.0029\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 0s 478us/step - loss: 4.4792e-04 - val_loss: 0.0025\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 0s 486us/step - loss: 4.2341e-04 - val_loss: 0.0023\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 0s 427us/step - loss: 3.9324e-04 - val_loss: 0.0023\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 0s 416us/step - loss: 3.5268e-04 - val_loss: 0.0021\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 0s 425us/step - loss: 3.2804e-04 - val_loss: 0.0022\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 0s 411us/step - loss: 2.9097e-04 - val_loss: 0.0019\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 0s 422us/step - loss: 2.8574e-04 - val_loss: 0.0021\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 0s 410us/step - loss: 2.4641e-04 - val_loss: 0.0018\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 0s 403us/step - loss: 2.5290e-04 - val_loss: 0.0019\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 2.3613e-04 - val_loss: 0.0018\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 0s 444us/step - loss: 2.3813e-04 - val_loss: 0.0019\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 0s 446us/step - loss: 2.3704e-04 - val_loss: 0.0018\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 0s 423us/step - loss: 2.3671e-04 - val_loss: 0.0018\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 0s 429us/step - loss: 2.3909e-04 - val_loss: 0.0018\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 0s 435us/step - loss: 2.3784e-04 - val_loss: 0.0018\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 0s 448us/step - loss: 2.3846e-04 - val_loss: 0.0018\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 0s 432us/step - loss: 2.3675e-04 - val_loss: 0.0018\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 0s 427us/step - loss: 2.3552e-04 - val_loss: 0.0018\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 2.3404e-04 - val_loss: 0.0018\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 0s 426us/step - loss: 2.3233e-04 - val_loss: 0.0018\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 0s 436us/step - loss: 2.3105e-04 - val_loss: 0.0018\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 0s 439us/step - loss: 2.2906e-04 - val_loss: 0.0018\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 0s 417us/step - loss: 2.2791e-04 - val_loss: 0.0018\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 0s 423us/step - loss: 2.2600e-04 - val_loss: 0.0018\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 0s 438us/step - loss: 2.2482e-04 - val_loss: 0.0018\n",
      "Epoch 74/300\n",
      " 576/1000 [================>.............] - ETA: 0s - loss: 1.4792e-04"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "#Reshape data for (Sample,Timestep,Features) \n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
    "#Fit model with history to check for overfitting\n",
    "history = model.fit(X_train,y_train,epochs=300,validation_data=(X_test,y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = model.predict(X_test)\n",
    "plt.plot(scl.inverse_transform(y_test.reshape(-1,1)))\n",
    "plt.plot(scl.inverse_transform(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = []\n",
    "pred = []\n",
    "#for i in range(250):\n",
    "i=249\n",
    "Xt = model.predict(X_test[i].reshape(1,7,1))\n",
    "print('predicted:{0}, actual:{1}'.format(scl.inverse_transform(Xt),scl.inverse_transform(y_test[i].reshape(-1,1))))\n",
    "pred.append(scl.inverse_transform(Xt))\n",
    "act.append(scl.inverse_transform(y_test[i].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'pred':list(np.reshape(pred, (-1))),'act':list(np.reshape(act, (-1)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = model.predict(X_test)\n",
    "plt.plot(scl.inverse_transform(y_test.reshape(-1,1)))\n",
    "plt.plot(scl.inverse_transform(Xt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[249]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
